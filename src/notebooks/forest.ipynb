{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Playground with Random Forest algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import os,sys\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "\n",
    "from helpers.features import *\n",
    "from helpers.data_helpers import *\n",
    "from helpers.image_helpers import *\n",
    "from helpers.helpers import *\n",
    "from helpers.constants import *\n",
    "from helpers.training import train\n",
    "from helpers.mask_to_submission import generate_submission_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading aerial 80 images, done.\n",
      "Loading 80 groundtruth images, done.\n",
      "before augment\n",
      "(50000, 16, 16, 3)\n",
      "after augment\n",
      "(50000, 16, 16, 3)\n",
      "\n",
      "Loading aerial 20 images, done.\n",
      "Loading 20 groundtruth images, done.\n",
      "before augment\n",
      "(12500, 16, 16, 3)\n",
      "after augment\n",
      "(12500, 16, 16, 3)\n",
      "\n",
      "Loading aerial 50 images, done.\n",
      "before augment\n",
      "(72200, 16, 16, 3)\n",
      "after augment\n",
      "(72200, 16, 16, 3)\n"
     ]
    }
   ],
   "source": [
    "if TRAIN : \n",
    "    trainset = AerialDataset(TRAIN_IMAGE_DATA,\n",
    "                             TRAIN_LABEL_DATA,\n",
    "                             range(1, TRAINING_SIZE + 1), \n",
    "                             IMG_PATCH_SIZE,\n",
    "                             None)\n",
    "    validationset = AerialDataset(TRAIN_IMAGE_DATA, TRAIN_LABEL_DATA, range(1 + TRAINING_SIZE, DATA_SIZE + 1), IMG_PATCH_SIZE, None, validation=True)\n",
    "    testset = AerialDataset(TEST_IMAGE_DATA, TEST_LABEL_DATA, range(1, TESTING_SIZE + 1), IMG_PATCH_SIZE, None, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "param_grid = {\n",
    "                 'n_estimators': [100],\n",
    "                 'max_leaf_nodes': [500],\n",
    "                 'max_depth': [20]\n",
    "             }\n",
    "\n",
    "rfc = RandomForestClassifier(random_state=20)\n",
    "#rfc_ada = AdaBoostClassifier(DecisionTreeClassifier(max_depth=1), random_state=20, n_estimators=500)\n",
    "rfc_gridsearch = GridSearchCV(rfc, param_grid=param_grid, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=20, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.asarray([extract_features(trainset.train_data[i]) for i in range(len(trainset.train_data))])\n",
    "X_validation = np.asarray([extract_features(validationset.train_data[i]) for i in range(len(validationset.train_data))])\n",
    "X_test = np.asarray([extract_features(testset.train_data[i]) for i in range(len(testset.train_data))])\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is used in order to test tuning hyper parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfc_gridsearch.fit(X, trainset.train_labels)\n",
    "results = pd.DataFrame(rfc_gridsearch.cv_results_)\n",
    "results.to_csv(path_or_buf='data/results_gridsearch.csv', encoding='utf8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.78768000000000005, array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.]]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "# max_depth=None, max_leaf_nodes=1500, n_estimators=800\n",
    "# max_depth=None, n_estimators=800\n",
    "rfc.set_params(max_depth=30, max_leaf_nodes=1500, n_estimators=120)\n",
    "rfc.fit(X, trainset.train_labels)\n",
    "\n",
    "y_val = rfc.predict(X_validation)\n",
    "accuracy = accuracy_score(validationset.train_labels, y_val, normalize=True)\n",
    "accuracy, y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.],\n",
       "        [ 0.,  1.]]), array([[ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        ..., \n",
       "        [ 1.,  0.],\n",
       "        [ 1.,  0.],\n",
       "        [ 0.,  1.]], dtype=float32))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_val, validationset.train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = rfc.predict(X_test)\n",
    "y_test_final = np.zeros((y_test.shape[0], ))\n",
    "y_test_final[y_test[:, 1] == 1] = 1\n",
    "generate_predictions(y_test_final, concatenate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/test/predictions/satImage_001.png\n",
      "./data/test/predictions/satImage_002.png\n",
      "./data/test/predictions/satImage_003.png\n",
      "./data/test/predictions/satImage_004.png\n",
      "./data/test/predictions/satImage_005.png\n",
      "./data/test/predictions/satImage_006.png\n",
      "./data/test/predictions/satImage_007.png\n",
      "./data/test/predictions/satImage_008.png\n",
      "./data/test/predictions/satImage_009.png\n",
      "./data/test/predictions/satImage_010.png\n",
      "./data/test/predictions/satImage_011.png\n",
      "./data/test/predictions/satImage_012.png\n",
      "./data/test/predictions/satImage_013.png\n",
      "./data/test/predictions/satImage_014.png\n",
      "./data/test/predictions/satImage_015.png\n",
      "./data/test/predictions/satImage_016.png\n",
      "./data/test/predictions/satImage_017.png\n",
      "./data/test/predictions/satImage_018.png\n",
      "./data/test/predictions/satImage_019.png\n",
      "./data/test/predictions/satImage_020.png\n",
      "./data/test/predictions/satImage_021.png\n",
      "./data/test/predictions/satImage_022.png\n",
      "./data/test/predictions/satImage_023.png\n",
      "./data/test/predictions/satImage_024.png\n",
      "./data/test/predictions/satImage_025.png\n",
      "./data/test/predictions/satImage_026.png\n",
      "./data/test/predictions/satImage_027.png\n",
      "./data/test/predictions/satImage_028.png\n",
      "./data/test/predictions/satImage_029.png\n",
      "./data/test/predictions/satImage_030.png\n",
      "./data/test/predictions/satImage_031.png\n",
      "./data/test/predictions/satImage_032.png\n",
      "./data/test/predictions/satImage_033.png\n",
      "./data/test/predictions/satImage_034.png\n",
      "./data/test/predictions/satImage_035.png\n",
      "./data/test/predictions/satImage_036.png\n",
      "./data/test/predictions/satImage_037.png\n",
      "./data/test/predictions/satImage_038.png\n",
      "./data/test/predictions/satImage_039.png\n",
      "./data/test/predictions/satImage_040.png\n",
      "./data/test/predictions/satImage_041.png\n",
      "./data/test/predictions/satImage_042.png\n",
      "./data/test/predictions/satImage_043.png\n",
      "./data/test/predictions/satImage_044.png\n",
      "./data/test/predictions/satImage_045.png\n",
      "./data/test/predictions/satImage_046.png\n",
      "./data/test/predictions/satImage_047.png\n",
      "./data/test/predictions/satImage_048.png\n",
      "./data/test/predictions/satImage_049.png\n",
      "./data/test/predictions/satImage_050.png\n"
     ]
    }
   ],
   "source": [
    "generate_submission_csv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
